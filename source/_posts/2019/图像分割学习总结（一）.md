---
title: 图像分割学习总结（一）
tags:
  - 图像分割
 
date: 2019-06-20 20:49:05
abbrlink: 79vmp
---
- 按分割目的划分
>普通分割
将不同分属不同物体的像素区域分开。 
如前景与后景分割开，狗的区域与猫的区域与背景分割开。

>语义分割   图像的语义分割（Semantic Segmentation）
在普通分割的基础上，分类出每一块区域的语义（即这块区域是什么物体）。 
如把画面中的所有物体都指出它们各自的类别。

>实例分割
在语义分割的基础上，给每个物体编号。 
如这个是该画面中的狗A，那个是画面中的狗B。


>Fully Convolutional Networks (FCN)

我们介绍的第一篇论文是Fully Convolutional Networks for Semantic Segmentation，简称FCN。这篇论文是第一篇成功使用深度学习做图像语义分割的论文。论文的主要贡献有两点：

提出了全卷积网络。将全连接网络替换成了卷积网络，使得网络可以接受任意大小的图片，并输出和原图一样大小的分割图。只有这样，才能为每个像素做分类。
使用了反卷积层（Deconvolution）。分类神经网络的特征图一般只有原图的几分之一大小。想要映射回原图大小必须对特征图进行上采样，这就是反卷积层的作用。虽然名字叫反卷积层，但其实它并不是卷积的逆操作，更合适的名字叫做转置卷积（Transposed Convolution），作用是从小的特征图卷出大的特征图。

>DeepLab
DeepLab有v1 v2 v3，第一篇名字叫做DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs。这一系列论文引入了以下几点比较重要的方法：

第一个是带洞卷积，英文名叫做Dilated Convolution，或者Atrous Convolution。带洞卷积实际上就是普通的卷积核中间插入了几个洞，如下图。



>Pyramid Scene Parsing Network
Pyramid Scene Parsing Network的核心贡献是Global Pyramid Pooling，翻译成中文叫做全局金字塔池化。它将特征图缩放到几个不同的尺寸，使得特征具有更好地全局和多尺度信息，这一点在准确率提升上上非常有用。


>Mask R-CNN
Mask R-CNN是大神何凯明的力作，将Object Detection与Semantic Segmentation合在了一起做。它的贡献主要是以下几点。

第一，神经网络有了多个分支输出。Mask R-CNN使用类似Faster R-CNN的框架，Faster R-CNN的输出是物体的bounding box和类别，而Mask R-CNN则多了一个分支，用来预测物体的语义分割图。也就是说神经网络同时学习两项任务，可以互相促进。

第二，在语义分割中使用Binary Mask。原来的语义分割预测类别需要使用0 1 2 3 4等数字代表各个类别。在Mask R-CNN中，检测分支会预测类别。这时候分割只需要用0 1预测这个物体的形状面具就行了。

第三，Mask R-CNN提出了RoiAlign用来替换Faster R-CNN中的RoiPooling。RoiPooling的思想是将输入图像中任意一块区域对应到神经网络特征图中的对应区域。RoiPooling使用了化整的近似来寻找对应区域，导致对应关系与实际情况有偏移。这个偏移在分类任务中可以容忍，但对于精细度更高的分割则影响较大。

为了解决这个问题，RoiAlign不再使用化整操作，而是使用线性插值来寻找更精准的对应区域。效果就是可以得到更好地对应。实验也证明了效果不错。下面展示了与之前方法的对比，下面的图是Mask R-CNN，可以看出精细了很多。



>U-Net
U-Net是原作者参加ISBI Challenge提出的一种分割网络，能够适应很小的训练集（大约30张图）。U-Net与FCN都是很小的分割网络，既没有使用空洞卷积，也没有后接CRF，结构简单。

类似于一个大大的U字母：首先进行Conv+Pooling下采样；然后Deconv反卷积进行上采样，crop之前的低层feature map，进行融合；然后再次上采样。重复这个过程，直到获得输出388x388x2的feature map，最后经过softmax获得output segment map。总体来说与FCN思路非常类似。

为何要提起U-Net？是因为U-Net采用了与FCN完全不同的特征融合方式：拼接！

语义分割网络在特征融合时也有2种办法：

FCN式的逐点相加，对应caffe的EltwiseLayer层，对应tensorflow的tf.add()
U-Net式的channel维度拼接融合，对应caffe的ConcatLayer层，对应tensorflow的tf.concat()

>FCN-全卷积网络
>CRF-条件随机场
>MRF-马尔科夫随机场

FCN
此处的FCN特指Fully Convolutional Networks for Semantic Segmentation论文中提出的结构，而非广义的全卷积网络。

作者的FCN主要使用了三种技术：

卷积化（Convolutional）
上采样（Upsample）
跳跃结构（Skip Layer）
>卷积化

卷积化即是将普通的分类网络，比如VGG16，ResNet50/101等网络丢弃全连接层，换上对应的卷积层即可。


>上采样

此处的上采样即是反卷积（Deconvolution）。当然关于这个名字不同框架不同，Caffe和Kera里叫Deconvolution，而tensorflow里叫conv_transpose。CS231n这门课中说，叫conv_transpose更为合适。

众所诸知，普通的池化（为什么这儿是普通的池化请看后文）会缩小图片的尺寸，比如VGG16 五次池化后图片被缩小了32倍。为了得到和原图等大的分割图，我们需要上采样/反卷积。

反卷积和卷积类似，都是相乘相加的运算。只不过后者是多对一，前者是一对多。而反卷积的前向和后向传播，只用颠倒卷积的前后向传播即可。所以无论优化还是后向传播算法都是没有问题


>跳跃结构

（这个奇怪的名字是我翻译的，好像一般叫忽略连接结构）这个结构的作用就在于优化结果，因为如果将全卷积之后的结果直接上采样得到的结果是很粗糙的，所以作者将不同池化层的结果进行上采样之后来优化输出




>SegNet/DeconvNet
这样的结构总结在这儿，只是我觉得结构上比较优雅，它得到的结果不一定比上一种好。


>DeepLab
接下来介绍一个很成熟优雅的结构，以至于现在的很多改进是基于这个网络结构的进行的。

首先这里我们将指出一个第一个结构FCN的粗糙之处：为了保证之后输出的尺寸不至于太小，FCN的作者在第一层直接对原图加了100的padding，可想而知，这会引入噪声。

而怎样才能保证输出的尺寸不会太小而又不会产生加100 padding这样的做法呢？可能有人会说减少池化层不就行了，这样理论上是可以的，但是这样直接就改变了原先可用的结构了，而且最重要的一点是就不能用以前的结构参数进行fine-tune了。所以，Deeplab这里使用了一个非常优雅的做法：将pooling的stride改为1，再加上 1 padding。这样池化后的图片尺寸并未减小，并且依然保留了池化整合特征的特性。

但是，事情还没完。因为池化层变了，后面的卷积的感受野也对应的改变了，这样也不能进行fine-tune了。所以，Deeplab提出了一种新的卷积，带孔的卷积：Atrous Convolution


>全连接条件随机场(DenseCRF)

对于每个像素i具有类别标签x_i还有对应的观测值y_i，这样每个像素点作为节点，像素与像素间的关系作为边，即构成了一个条件随机场。而且我们通过观测变量y_i来推测像素i对应的类别标签x_i。条件随机场如下：




２０１５年提出的ＳｅｇＮｅｔ网络是由编码器和解码器
构成的分割网络
前半部分是由卷积层和池化层
组成的编码器，后半部分是由卷积层和上采样层组成
的解码器。ＳｅｇＮｅｔ网络中，编码器提取特征图像，解码
器将特征图像返回到输入图像的原始尺寸，以此方式
实现端到端的网络结构。
在此之后，又有大批的分割网络涌现出来。但大
多都在ＦＣＮ的基础上一步步发展而来。下面对全卷
积网络的主要构成进行概述


传统：水平集，区域生长，阈值，分水岭

基于阈值分割，基于边缘分割，基于聚类分
割，基于轮廓分割，基于区域分割以及卷积神经网络

>区域生长：
该方法通过定义一个生长规则，然后在每一个Ｐ域内寻找一个种子像素，通过对
图像进行扫描，依次在种子点周围邻域内寻找满足生长规则的像素并将其合并
到种子所在的区域，然后再检查该区域的全部相邻点，并把满足生长准则的点
合并到该区域，不断重复该过程直到找不到满足条件的像素为止。

对于噪声过多和灰度值不均匀的图像容易产生欠拟合和过拟合的问题

>分水岭算法
基于拓扑理论，通过模拟形态学
的方法进行图像分割

>水平集算法








